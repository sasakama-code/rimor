name: ğŸš€ External Project Benchmark

on:
  # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«å®Ÿè¡Œ
  workflow_dispatch:
    inputs:
      tier:
        description: 'ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¯¾è±¡ãƒ†ã‚£ã‚¢'
        required: true
        default: '1'
        type: choice
        options:
          - '1'  # Tier 1: TypeScript, Ant Design, VS Code
          - '2'  # Tier 2: Material UI, Storybook, Deno
          - 'all'  # å…¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
      baseline_comparison:
        description: 'ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµ±åˆæ©Ÿèƒ½ã‚’ä½¿ç”¨'
        required: true
        default: true
        type: boolean
      generate_reports:
        description: 'å…¨å½¢å¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ'
        required: true
        default: true
        type: boolean
      
  # å®šæœŸå®Ÿè¡Œï¼ˆæ¯é€±æ—¥æ›œ AM 3:00 JSTï¼‰
  schedule:
    - cron: '0 18 * * 0'  # 18:00 UTC = 3:00 JST+9
    
  # PRã§ã®å®Ÿè¡Œï¼ˆdrafté™¤ãï¼‰
  pull_request:
    branches: [ main ]
    types: [opened, synchronize, ready_for_review]
    paths:
      - 'src/benchmark/**'
      - 'scripts/benchmark-external-projects.ts'
      - '.github/workflows/benchmark-external.yml'

env:
  NODE_VERSION: '20.x'
  BENCHMARK_TIMEOUT: '1800000'  # 30 minutes
  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

jobs:
  # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±ç¢ºèª
  system-check:
    name: ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
    runs-on: ubuntu-latest
    
    outputs:
      can_run_tier1: ${{ steps.resource_check.outputs.tier1_ready }}
      can_run_tier2: ${{ steps.resource_check.outputs.tier2_ready }}
      recommended_projects: ${{ steps.resource_check.outputs.recommended }}
      
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build optimized
      run: npm run build:ci
      
    - name: ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
      id: resource_check
      run: |
        echo "ğŸ” ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèªä¸­..."
        
        # CPUãƒ»ãƒ¡ãƒ¢ãƒªæƒ…å ±å–å¾—
        CPU_CORES=$(nproc)
        TOTAL_MEMORY=$(free -m | awk 'NR==2{printf "%.1f", $2/1024}')
        AVAILABLE_MEMORY=$(free -m | awk 'NR==2{printf "%.1f", $7/1024}')
        DISK_SPACE=$(df -h . | awk 'NR==2{print $4}')
        
        echo "CPU cores: $CPU_CORES"
        echo "Total memory: ${TOTAL_MEMORY}GB"
        echo "Available memory: ${AVAILABLE_MEMORY}GB"
        echo "Available disk: $DISK_SPACE"
        
        # Tier 1å®Ÿè¡Œå¯èƒ½æ€§åˆ¤å®š
        if (( CPU_CORES >= 2 && $(echo "$AVAILABLE_MEMORY >= 4.0" | bc -l) )); then
          echo "tier1_ready=true" >> $GITHUB_OUTPUT
          echo "âœ… Tier 1ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè¡Œå¯èƒ½"
        else
          echo "tier1_ready=false" >> $GITHUB_OUTPUT
          echo "âŒ Tier 1ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè¡Œä¸å¯ï¼ˆãƒªã‚½ãƒ¼ã‚¹ä¸è¶³ï¼‰"
        fi
        
        # Tier 2å®Ÿè¡Œå¯èƒ½æ€§åˆ¤å®š
        if (( CPU_CORES >= 4 && $(echo "$AVAILABLE_MEMORY >= 6.0" | bc -l) )); then
          echo "tier2_ready=true" >> $GITHUB_OUTPUT
          echo "âœ… Tier 2ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè¡Œå¯èƒ½"
        else
          echo "tier2_ready=false" >> $GITHUB_OUTPUT
          echo "âš ï¸ Tier 2ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Ÿè¡Œåˆ¶é™ã‚ã‚Š"
        fi
        
        # æ¨å¥¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè¨­å®š
        if (( CPU_CORES >= 4 )); then
          echo "recommended=all" >> $GITHUB_OUTPUT
        else
          echo "recommended=tier1" >> $GITHUB_OUTPUT
        fi

  # Tier 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
  benchmark-tier1:
    name: Tier 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    runs-on: ubuntu-latest
    needs: system-check
    if: needs.system-check.outputs.can_run_tier1 == 'true' && (github.event.inputs.tier == '1' || github.event.inputs.tier == 'all' || github.event_name == 'schedule')
    
    outputs:
      benchmark_success: ${{ steps.benchmark.outputs.success }}
      report_url: ${{ steps.benchmark.outputs.report_url }}
      baseline_id: ${{ steps.benchmark.outputs.baseline_id }}
      
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build optimized
      run: npm run build:ci
      
    - name: ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–
      run: |
        echo "ğŸ”§ GitHub Actions runneræœ€é©åŒ–..."
        
        # Gitè¨­å®šæœ€é©åŒ–
        git config --global gc.auto 0
        git config --global core.preloadindex true
        git config --global core.fscache true
        
        # Node.jsæœ€é©åŒ–
        export NODE_OPTIONS="--max-old-space-size=4096"
        echo "NODE_OPTIONS=$NODE_OPTIONS" >> $GITHUB_ENV
        
        # ä¸¦åˆ—å‡¦ç†æœ€é©åŒ–
        export UV_THREADPOOL_SIZE=4
        echo "UV_THREADPOOL_SIZE=4" >> $GITHUB_ENV
        
        echo "âœ… ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–å®Œäº†"
      
    - name: Tier 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
      id: benchmark
      timeout-minutes: 25
      run: |
        echo "ğŸš€ Tier 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œé–‹å§‹..."
        
        mkdir -p .rimor/benchmark-results/reports
        
        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµ±åˆãƒ¢ãƒ¼ãƒ‰åˆ¤å®š
        BASELINE_FLAG=""
        if [[ "${{ github.event.inputs.baseline_comparison }}" == "true" || "${{ github.event_name }}" == "schedule" ]]; then
          BASELINE_FLAG="--baseline-comparison"
          echo "ğŸ“Š ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµ±åˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ"
        fi
        
        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
        if timeout 1500 npm run benchmark:external -- \
          --tier=1 \
          $BASELINE_FLAG \
          --verbose \
          --output=.rimor/benchmark-results \
          --timeout=300000 \
          --max-retries=2; then
          
          echo "success=true" >> $GITHUB_OUTPUT
          echo "âœ… Tier 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æˆåŠŸ"
          
          # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
          LATEST_REPORT=$(find .rimor/benchmark-results/reports -name "*.json" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2-)
          if [[ -n "$LATEST_REPORT" ]]; then
            echo "report_url=$LATEST_REPORT" >> $GITHUB_OUTPUT
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³IDæŠ½å‡ºï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
            if [[ -f "$LATEST_REPORT" ]] && grep -q "baselineId" "$LATEST_REPORT"; then
              BASELINE_ID=$(jq -r '.baselineId // empty' "$LATEST_REPORT" 2>/dev/null || echo "")
              if [[ -n "$BASELINE_ID" ]]; then
                echo "baseline_id=$BASELINE_ID" >> $GITHUB_OUTPUT
              fi
            fi
          fi
          
        else
          echo "success=false" >> $GITHUB_OUTPUT
          echo "âŒ Tier 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¤±æ•—ã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ"
          exit 1
        fi
      
    - name: çµæœã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: tier1-benchmark-results
        path: .rimor/benchmark-results/
        retention-days: 30
        
    - name: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™æŠ½å‡º
      if: steps.benchmark.outputs.success == 'true'
      run: |
        echo "ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™æŠ½å‡º..."
        
        # æœ€æ–°ã®çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æŒ‡æ¨™æŠ½å‡º
        LATEST_REPORT="${{ steps.benchmark.outputs.report_url }}"
        if [[ -f "$LATEST_REPORT" ]]; then
          echo "## Tier 1 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ ğŸš€" >> performance_summary.md
          echo "" >> performance_summary.md
          
          # JSONçµæœã‹ã‚‰æŒ‡æ¨™æŠ½å‡ºï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
          if AVG_TIME=$(jq -r '.results[]? | select(.success==true) | .performance.timePerFile' "$LATEST_REPORT" 2>/dev/null | awk '{sum+=$1; count++} END {if(count>0) printf "%.2f", sum/count; else print "N/A"}'); then
            echo "- **å¹³å‡å®Ÿè¡Œæ™‚é–“**: ${AVG_TIME}ms/file" >> performance_summary.md
          fi
          
          if SUCCESS_COUNT=$(jq -r '[.results[]? | select(.success==true)] | length' "$LATEST_REPORT" 2>/dev/null); then
            TOTAL_COUNT=$(jq -r '.results | length' "$LATEST_REPORT" 2>/dev/null)
            if [[ "$TOTAL_COUNT" -gt 0 ]]; then
              SUCCESS_RATE=$((SUCCESS_COUNT * 100 / TOTAL_COUNT))
              echo "- **æˆåŠŸç‡**: ${SUCCESS_RATE}% (${SUCCESS_COUNT}/${TOTAL_COUNT})" >> performance_summary.md
            fi
          fi
          
          if TARGET_5MS_COUNT=$(jq -r '[.results[]? | select(.success==true and .target5ms.achieved==true)] | length' "$LATEST_REPORT" 2>/dev/null); then
            SUCCESSFUL_COUNT=$(jq -r '[.results[]? | select(.success==true)] | length' "$LATEST_REPORT" 2>/dev/null)
            if [[ "$SUCCESSFUL_COUNT" -gt 0 ]]; then
              TARGET_5MS_RATE=$((TARGET_5MS_COUNT * 100 / SUCCESSFUL_COUNT))
              echo "- **5ms/fileç›®æ¨™é”æˆç‡**: ${TARGET_5MS_RATE}% (${TARGET_5MS_COUNT}/${SUCCESSFUL_COUNT})" >> performance_summary.md
            fi
          fi
          
          echo "" >> performance_summary.md
          echo "### ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥çµæœ" >> performance_summary.md
          echo "" >> performance_summary.md
          echo "| ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | æ™‚é–“(ms/file) | 5msç›®æ¨™ | çŠ¶æ…‹ |" >> performance_summary.md
          echo "|------------|---------------|---------|------|" >> performance_summary.md
          
          # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥çµæœï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
          if jq -r '.results[]? | [.projectName, .performance.timePerFile, .target5ms.achieved, .success] | @tsv' "$LATEST_REPORT" 2>/dev/null | while IFS=$'\t' read -r project time target5ms success; do
            target_icon=$([ "$target5ms" = "true" ] && echo "âœ…" || echo "âŒ")
            status_icon=$([ "$success" = "true" ] && echo "âœ…" || echo "âŒ")
            printf "| %s | %.2f | %s | %s |\n" "$project" "$time" "$target_icon" "$status_icon"
          done >> performance_summary.md 2>/dev/null || echo "| ã‚¨ãƒ©ãƒ¼ | N/A | âŒ | âŒ |" >> performance_summary.md; then
            echo "æŒ‡æ¨™æŠ½å‡ºå®Œäº†"
          fi
        fi
        
        cat performance_summary.md || echo "æŒ‡æ¨™æŠ½å‡ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ"

  # Tier 2 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
  benchmark-tier2:
    name: Tier 2 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    runs-on: ubuntu-latest
    needs: system-check
    if: needs.system-check.outputs.can_run_tier2 == 'true' && (github.event.inputs.tier == '2' || github.event.inputs.tier == 'all') && github.event_name != 'pull_request'
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build optimized
      run: npm run build:ci
      
    - name: Tier 2 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
      timeout-minutes: 35
      run: |
        echo "ğŸš€ Tier 2 ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œé–‹å§‹..."
        
        BASELINE_FLAG=""
        if [[ "${{ github.event.inputs.baseline_comparison }}" == "true" || "${{ github.event_name }}" == "schedule" ]]; then
          BASELINE_FLAG="--baseline-comparison"
        fi
        
        npm run benchmark:external -- \
          --tier=2 \
          $BASELINE_FLAG \
          --verbose \
          --output=.rimor/benchmark-results \
          --timeout=400000 \
          --max-retries=2
        
    - name: Tier 2 çµæœã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆä¿å­˜
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: tier2-benchmark-results
        path: .rimor/benchmark-results/
        retention-days: 30

  # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
  generate-reports:
    name: ğŸ“Š çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    runs-on: ubuntu-latest
    needs: [system-check, benchmark-tier1]
    if: always() && (needs.benchmark-tier1.outputs.benchmark_success == 'true') && (github.event.inputs.generate_reports == 'true' || github.event_name == 'schedule')
    
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        
    - name: Install dependencies
      run: npm ci
      
    - name: Build optimized
      run: npm run build:ci
      
    - name: Download benchmark results
      uses: actions/download-artifact@v4
      with:
        name: tier1-benchmark-results
        path: .rimor/benchmark-results/
        
    - name: çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
      run: |
        echo "ğŸ“Š çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹..."
        
        # TypeScriptã§ãƒ¬ãƒãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ç›´æ¥å®Ÿè¡Œ
        # ï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€BenchmarkReportGeneratorã‚’ä½¿ç”¨ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆï¼‰
        
        mkdir -p .rimor/reports/{markdown,html,csv,dashboard}
        
        # åŸºæœ¬çš„ãªMarkdownãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        echo "# ğŸš€ Rimor å¤–éƒ¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ ãƒ¬ãƒãƒ¼ãƒˆ" > .rimor/reports/benchmark-report.md
        echo "" >> .rimor/reports/benchmark-report.md
        echo "**ç”Ÿæˆæ—¥æ™‚**: $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> .rimor/reports/benchmark-report.md
        echo "" >> .rimor/reports/benchmark-report.md
        
        # çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        LATEST_RESULT=$(find .rimor/benchmark-results/reports -name "*.json" -type f 2>/dev/null | head -1)
        if [[ -n "$LATEST_RESULT" && -f "$LATEST_RESULT" ]]; then
          echo "## ğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼" >> .rimor/reports/benchmark-report.md
          echo "" >> .rimor/reports/benchmark-report.md
          
          # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°
          PROJECT_COUNT=$(jq -r '.results | length' "$LATEST_RESULT" 2>/dev/null || echo "0")
          echo "- **å¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°**: $PROJECT_COUNT" >> .rimor/reports/benchmark-report.md
          
          # æˆåŠŸç‡
          SUCCESS_COUNT=$(jq -r '[.results[] | select(.success==true)] | length' "$LATEST_RESULT" 2>/dev/null || echo "0")
          echo "- **æˆåŠŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ•°**: $SUCCESS_COUNT" >> .rimor/reports/benchmark-report.md
          
          # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æƒ…å ±
          if BASELINE_ID=$(jq -r '.baselineId // empty' "$LATEST_RESULT" 2>/dev/null) && [[ -n "$BASELINE_ID" ]]; then
            echo "- **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ID**: \`$BASELINE_ID\`" >> .rimor/reports/benchmark-report.md
          fi
          
          # æ¯”è¼ƒæƒ…å ±
          if jq -e '.comparison' "$LATEST_RESULT" >/dev/null 2>&1; then
            IMPROVEMENT=$(jq -r '.comparison.overallImprovement' "$LATEST_RESULT" 2>/dev/null || echo "N/A")
            echo "- **å…¨ä½“æ”¹å–„ç‡**: ${IMPROVEMENT}%" >> .rimor/reports/benchmark-report.md
          fi
          
          echo "" >> .rimor/reports/benchmark-report.md
          echo "## ğŸ¯ 5ms/file ç›®æ¨™é”æˆçŠ¶æ³" >> .rimor/reports/benchmark-report.md
          echo "" >> .rimor/reports/benchmark-report.md
          
          # 5msç›®æ¨™é”æˆã®è©³ç´°
          if jq -r '.results[] | [.projectName, .performance.timePerFile, .target5ms.achieved] | @tsv' "$LATEST_RESULT" 2>/dev/null | while IFS=$'\t' read -r project time achieved; do
            icon=$([ "$achieved" = "true" ] && echo "âœ…" || echo "âŒ")
            printf "- %s **%s**: %.2fms/file %s\n" "$icon" "$project" "$time" "$icon"
          done >> .rimor/reports/benchmark-report.md; then
            echo "âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†"
          fi
        fi
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆï¼ˆç°¡ç•¥ç‰ˆï¼‰
        cat > .rimor/reports/html/benchmark-report.html << 'EOF'
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rimor ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body { font-family: -apple-system, BlinkMacSystemFont, sans-serif; max-width: 1000px; margin: 0 auto; padding: 2rem; }
        .header { text-align: center; background: #f8f9fa; padding: 2rem; border-radius: 8px; margin-bottom: 2rem; }
        .metric-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 1rem; margin: 2rem 0; }
        .metric { background: white; padding: 1.5rem; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); text-align: center; }
        .metric-value { font-size: 2rem; font-weight: bold; color: #007bff; }
        .metric-label { color: #6c757d; margin-top: 0.5rem; }
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸš€ Rimor å¤–éƒ¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯</h1>
        <p>GitHub Actionsè‡ªå‹•å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆ</p>
    </div>
    
    <div class="metric-grid">
        <div class="metric">
            <div class="metric-value" id="projectCount">-</div>
            <div class="metric-label">å¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ</div>
        </div>
        <div class="metric">
            <div class="metric-value" id="successRate">-</div>
            <div class="metric-label">æˆåŠŸç‡</div>
        </div>
        <div class="metric">
            <div class="metric-value" id="avgTime">-</div>
            <div class="metric-label">å¹³å‡å®Ÿè¡Œæ™‚é–“(ms/file)</div>
        </div>
        <div class="metric">
            <div class="metric-value" id="target5msRate">-</div>
            <div class="metric-label">5msç›®æ¨™é”æˆç‡</div>
        </div>
    </div>
    
    <script>
        // å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€çµæœJSONã‹ã‚‰å‹•çš„ã«å€¤ã‚’è¨­å®š
        document.getElementById('projectCount').textContent = 'N/A';
        document.getElementById('successRate').textContent = 'N/A';
        document.getElementById('avgTime').textContent = 'N/A';
        document.getElementById('target5msRate').textContent = 'N/A';
    </script>
</body>
</html>
EOF
        
        echo "âœ… çµ±åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†"
        
    - name: Upload generated reports
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-reports
        path: .rimor/reports/
        retention-days: 90

  # PR ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
  comment-on-pr:
    name: ğŸ’¬ PRçµæœã‚³ãƒ¡ãƒ³ãƒˆ
    runs-on: ubuntu-latest
    needs: [benchmark-tier1, generate-reports]
    if: github.event_name == 'pull_request' && needs.benchmark-tier1.outputs.benchmark_success == 'true'
    
    permissions:
      pull-requests: write
      
    steps:
    - name: Download performance summary
      if: needs.benchmark-tier1.outputs.benchmark_success == 'true'
      uses: actions/download-artifact@v4
      with:
        name: tier1-benchmark-results
        path: ./results/
        
    - name: PR ã‚³ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          
          // çµæœãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æƒ…å ±æŠ½å‡º
          let performanceInfo = "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚";
          
          try {
            const resultsDir = './results/reports';
            if (fs.existsSync(resultsDir)) {
              const files = fs.readdirSync(resultsDir);
              const jsonFiles = files.filter(f => f.endsWith('.json'));
              
              if (jsonFiles.length > 0) {
                const latestFile = jsonFiles[jsonFiles.length - 1];
                const resultData = JSON.parse(fs.readFileSync(`${resultsDir}/${latestFile}`, 'utf8'));
                
                const successfulResults = resultData.results ? resultData.results.filter(r => r.success) : [];
                const totalResults = resultData.results ? resultData.results.length : 0;
                
                if (successfulResults.length > 0) {
                  const avgTime = successfulResults.reduce((sum, r) => sum + r.performance.timePerFile, 0) / successfulResults.length;
                  const target5msCount = successfulResults.filter(r => r.target5ms && r.target5ms.achieved).length;
                  const target5msRate = (target5msCount / successfulResults.length * 100).toFixed(1);
                  const successRate = (successfulResults.length / totalResults * 100).toFixed(1);
                  
                  performanceInfo = `
## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµæœ

| æŒ‡æ¨™ | å€¤ |
|------|-----|
| å¹³å‡å®Ÿè¡Œæ™‚é–“ | ${avgTime.toFixed(2)}ms/file |
| æˆåŠŸç‡ | ${successRate}% (${successfulResults.length}/${totalResults}) |
| 5ms/fileç›®æ¨™é”æˆç‡ | ${target5msRate}% (${target5msCount}/${successfulResults.length}) |

### ğŸ¯ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ¥çµæœ

| ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ | å®Ÿè¡Œæ™‚é–“ | 5msç›®æ¨™ |
|------------|---------|---------|`;

                  successfulResults.forEach(result => {
                    const targetIcon = result.target5ms && result.target5ms.achieved ? 'âœ…' : 'âŒ';
                    performanceInfo += `\n| ${result.projectName} | ${result.performance.timePerFile.toFixed(2)}ms | ${targetIcon} |`;
                  });

                  // ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒæƒ…å ±
                  if (resultData.comparison) {
                    performanceInfo += `\n\n### ğŸ“ˆ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æ¯”è¼ƒ\n\n`;
                    performanceInfo += `**å…¨ä½“æ”¹å–„ç‡**: ${resultData.comparison.overallImprovement.toFixed(2)}%\n`;
                  }
                  
                  // ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³æƒ…å ±
                  if (resultData.baselineId) {
                    performanceInfo += `\n**ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ID**: \`${resultData.baselineId}\``;
                  }
                }
              }
            }
          } catch (error) {
            console.error('çµæœãƒ•ã‚¡ã‚¤ãƒ«è§£æã‚¨ãƒ©ãƒ¼:', error);
            performanceInfo = `çµæœãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: ${error.message}`;
          }
          
          const comment = `
## ğŸš€ å¤–éƒ¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ

${performanceInfo}

---
### ğŸ“‹ å®Ÿè¡Œæƒ…å ±
- **å®Ÿè¡Œæ™‚åˆ»**: ${new Date().toLocaleString('ja-JP', { timeZone: 'Asia/Tokyo' })} JST
- **å¯¾è±¡ãƒ†ã‚£ã‚¢**: Tier 1 (TypeScript, Ant Design, VS Code)
- **ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³çµ±åˆ**: ${{ needs.benchmark-tier1.outputs.baseline_id && 'âœ… æœ‰åŠ¹' || 'â– ç„¡åŠ¹' }}

<details>
<summary>ğŸ“ æˆæœç‰©ã¨ãƒ­ã‚°</summary>

- ğŸ“Š [ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚¢ãƒ¼ãƒ†ã‚£ãƒ•ã‚¡ã‚¯ãƒˆ](${context.payload.pull_request.html_url}/checks)
- ğŸ” [è©³ç´°ãƒ­ã‚°](${context.payload.pull_request.html_url}/checks)

</details>

> ğŸ¤– ã“ã®ã‚³ãƒ¡ãƒ³ãƒˆã¯ GitHub Actions ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ
> ğŸ’¡ æ€§èƒ½ã«é–¢ã™ã‚‹è©³ç´°ãªåˆ†æã¯ã€ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”ç¢ºèªãã ã•ã„
          `.trim();
          
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.payload.pull_request.number,
            body: comment
          });

  # å®Ÿè¡Œå®Œäº†ã‚µãƒãƒªãƒ¼
  benchmark-summary:
    name: ğŸ“‹ å®Ÿè¡Œå®Œäº†ã‚µãƒãƒªãƒ¼
    runs-on: ubuntu-latest
    needs: [system-check, benchmark-tier1, benchmark-tier2, generate-reports]
    if: always()
    
    steps:
    - name: å®Ÿè¡Œã‚µãƒãƒªãƒ¼ç”Ÿæˆ
      run: |
        echo "## ğŸš€ å¤–éƒ¨ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ å®Ÿè¡Œå®Œäº†"
        echo ""
        echo "### ğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼"
        echo "- **ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª**: ${{ needs.system-check.result }}"
        echo "- **Tier 1å®Ÿè¡Œ**: ${{ needs.benchmark-tier1.result }}"
        echo "- **Tier 2å®Ÿè¡Œ**: ${{ needs.benchmark-tier2.result || 'ã‚¹ã‚­ãƒƒãƒ—' }}"
        echo "- **ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ**: ${{ needs.generate-reports.result || 'ã‚¹ã‚­ãƒƒãƒ—' }}"
        echo ""
        
        if [[ "${{ needs.benchmark-tier1.outputs.benchmark_success }}" == "true" ]]; then
          echo "âœ… **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æˆåŠŸ** - 5ms/fileç›®æ¨™é”æˆç‡ã®ç¶™ç¶šçš„ãªç›£è¦–ã‚’å®Ÿæ–½ä¸­"
          echo ""
          echo "### ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯"
          echo "- ğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœ: GitHub Actions Artifacts"
          echo "- ğŸ“ˆ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: ç”Ÿæˆã•ã‚ŒãŸHTMLãƒ¬ãƒãƒ¼ãƒˆ"
          if [[ -n "${{ needs.benchmark-tier1.outputs.baseline_id }}" ]]; then
            echo "- ğŸ“‹ ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: \`${{ needs.benchmark-tier1.outputs.baseline_id }}\`"
          fi
        else
          echo "âŒ **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å¤±æ•—** - ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦å•é¡Œã‚’ç‰¹å®šã—ã¦ãã ã•ã„"
        fi
        
        echo ""
        echo "---"
        echo "*å®Ÿè¡Œæ™‚åˆ»: $(date -u +"%Y-%m-%d %H:%M:%S UTC")*"